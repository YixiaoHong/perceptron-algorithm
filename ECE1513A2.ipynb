{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECE1513A2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lgr_ChwgrSbj","colab_type":"text"},"source":["# ECE1513 - Winter 2020\n","## Assignment 2\n","### Yixiao Hong 1001311145"]},{"cell_type":"markdown","metadata":{"id":"vrvdkGtrry4u","colab_type":"text"},"source":["### Dataset Preparation"]},{"cell_type":"code","metadata":{"id":"OLcTzHhlBHPH","colab_type":"code","outputId":"daeef90b-1e68-43b4-ab52-f0e10097de34","executionInfo":{"status":"ok","timestamp":1580679091619,"user_tz":300,"elapsed":938,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":445}},"source":["#import libs\n","import numpy as np\n","import pandas as pd\n","\n","#import dataset\n","from sklearn.datasets import load_breast_cancer\n","breast_cancer = load_breast_cancer()\n","\n","#Extract data\n","X = breast_cancer.data\n","#Extract targets\n","Y = breast_cancer.target\n","\n","#Extract training data\n","train_X = X[:450]\n","#Extract training data\n","test_X = X[450:]\n","#Extract testing targets\n","train_Y = Y[:450]\n","#Extract testing targets\n","test_Y = Y[450:]\n","\n","#display first 5 data features\n","print(\"First 5 data points (features)\")\n","display(pd.DataFrame(X).head())\n","#display first 5 data targets\n","print(\"First 5 data points (targets)\")\n","display(pd.DataFrame(Y).head())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["First 5 data points (features)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0      1       2       3   ...      26      27      28       29\n","0  17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n","1  20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n","2  19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n","3  11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n","4  20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n","\n","[5 rows x 30 columns]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["First 5 data points (targets)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0\n","0  0\n","1  0\n","2  0\n","3  0\n","4  0"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZgZLO7Xvr8W5","colab_type":"text"},"source":["### Problem2.2\n","###  (8 points) Implement this modified perceptron algorithm in Python and NumPy. Include a copy of your code in your submission for this assignment."]},{"cell_type":"markdown","metadata":{"id":"KY-zaZtEtXap","colab_type":"text"},"source":["#### Implement the perceptron algorithm"]},{"cell_type":"code","metadata":{"id":"uZ-q81fZOt3r","colab_type":"code","colab":{}},"source":["#Define the perceptiron algorithm function\n","def perceptron(train_X,train_Y,Lr,max_iter):\n","  \"\"\"\n","  Inputs:\n","  tranin_X(npArray): the train data features\n","  train_Y(npArray): the train data targets\n","  max_iter(int): the maximun iterations\n","  \n","  Outputs:\n","  w(npArray):the trained weight matrix\n","  b(float):the trained bias term\n","  \"\"\"\n","  #correst the tratgets from data set, make all 0 to be -1\n","  train_Y = np.where(train_Y==0, -1, train_Y)\n","  #Set up initial value of the weight\n","  w = np.zeros(len(train_X[0]))\n","  b = 0\n","  #Start the training\n","  for _ in range(max_iter):\n","    #set up the update flag\n","    update_flag = False\n","    for Xi, ti in zip(train_X,train_Y):\n","      zi = np.dot(Xi.T, w) + b\n","      if float(zi*ti) <= 0:\n","        #needs to update w and b\n","        w = w + Lr*np.dot(Xi.T, ti)\n","        b = b + Lr*ti\n","        update_flag = True\n","    if not update_flag:\n","      print(\"The weights and bias term converged\")\n","      break\n","  if update_flag:\n","    print(\"Exceeds the max_iter, training end\")\n","  return(w,b)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KCYxvuycteg1","colab_type":"text"},"source":["#### Perform the training using the function developed above "]},{"cell_type":"code","metadata":{"id":"OpqaoEwttUIU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"5652d24e-dc64-409d-a571-bcd96a7dca31","executionInfo":{"status":"ok","timestamp":1580679103741,"user_tz":300,"elapsed":13041,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}}},"source":["#train the classifier with train data\n","#here we set the max iteration be 10000\n","print(\"===>Start the training\\n\")\n","w,b = perceptron(train_X,train_Y,1,10000)\n","print(\"\\n===>Train finished:\")\n","print(\"\\n==>Trained w=:\\n\",w,\"\\n\\n==>Trained b=\\n\",b)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["===>Start the training\n","\n","Exceeds the max_iter, training end\n","\n","===>Train finished:\n","\n","==>Trained w=:\n"," [103003.70599992 -15846.22000007 185366.87999993  -6956.6\n","  -2724.49909    -13820.22614001 -19447.8850209   -7691.45253399\n","  -3562.4856      -1065.76898      2310.3296      10259.0284\n"," -19625.40059998 -17486.44999997   -316.339701    -3142.182471\n","  -4254.3529819    -899.798401    -1185.348957     -238.7286058\n"," 104882.68199998 -53353.99999992 -96301.67999996  -3329.7\n","  -4763.45449    -44815.94142004 -54303.73955601 -14413.09809597\n"," -11790.29380001  -4332.38642999] \n","\n","==>Trained b=\n"," 12938\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qkLl_Z8PuM6g","colab_type":"text"},"source":["#### Report the test error of your perceptron on the breast cancer dataset included with sklearn. Split the dataset (which includes 569 points) in 450 training examples and 119 test examples."]},{"cell_type":"code","metadata":{"id":"fH0X7fNbuNUG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"9c481ed7-7f6d-45e7-e728-3d4686c1d9eb","executionInfo":{"status":"ok","timestamp":1580679103745,"user_tz":300,"elapsed":13035,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}}},"source":["#use the trained classifier to predict the test examples\n","predict = np.dot(test_X,w.T) + b\n","\n","print(\"==> predicted targets for the test data\")\n","#correct the prediction result to binary term 1/0\n","predict = np.where(predict>=0, 1, predict)\n","predict = np.where(predict<0, 0, predict)\n","predict = predict.astype(int)\n","print(predict)\n","\n","print(\"==> original true targets for the test data:\")\n","print(test_Y)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["==> predicted targets for the test data\n","[1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1\n"," 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 0 0 0 0 0 0 1]\n","==> original true targets for the test data:\n","[1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n"," 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1\n"," 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 0 0 0 0 0 0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"90ad0YGcwcIk","colab_type":"text"},"source":["#### Report the test error"]},{"cell_type":"code","metadata":{"id":"RLvGQRjDvNM5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"cf3fcaa2-7f3a-4f05-aecb-50331b8b67c8","executionInfo":{"status":"ok","timestamp":1580679103747,"user_tz":300,"elapsed":13029,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}}},"source":["#calculate the test error\n","from sklearn.metrics import confusion_matrix\n","tn, fp, fn, tp = confusion_matrix(test_Y, predict).ravel()\n","print(\"==>True Positive Rate (Recall)\\n  = tp/(tp+fn):\\n  =\",round((tp/(tp+fn))*100,2),\"%\")\n","print(\"==>True Negative Rate (Selectivity)\\n  = tn/(tn+fp):\\n  =\",round((tn/(tn+fp))*100,2),\"%\")\n","\n","from sklearn.metrics import accuracy_score\n","print(\"==>Accuracy\\n  = (tp+tn)/(tp+tn+fp+fn)\\n  =\",round((accuracy_score(test_Y, predict))*100,2),\"%\")\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["==>True Positive Rate (Recall)\n","  = tp/(tp+fn):\n","  = 97.83 %\n","==>True Negative Rate (Selectivity)\n","  = tn/(tn+fp):\n","  = 85.19 %\n","==>Accuracy\n","  = (tp+tn)/(tp+tn+fp+fn)\n","  = 94.96 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yzSK7yevz7tT","colab_type":"text"},"source":["#### The results appears to be good with True Positive Rate = 97.83% , True Negative Rate = 85.19% and Accuracy = 94.96%"]}]}